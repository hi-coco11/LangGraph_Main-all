{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b13a764",
   "metadata": {},
   "source": [
    "##### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2472f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface==0.1.2\n",
      "  Obtaining dependency information for langchain-huggingface==0.1.2 from https://files.pythonhosted.org/packages/9d/f8/77a303ddc492f6eed8bf0979f2bc6db4fa6eb1089c5e9f0f977dd87bc9c2/langchain_huggingface-0.1.2-py3-none-any.whl.metadata\n",
      "  Using cached langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-huggingface==0.1.2) (0.30.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-huggingface==0.1.2) (0.3.58)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface==0.1.2)\n",
      "  Obtaining dependency information for sentence-transformers>=2.6.0 from https://files.pythonhosted.org/packages/45/2d/1151b371f28caae565ad384fdc38198f1165571870217aedda230b9d7497/sentence_transformers-4.1.0-py3-none-any.whl.metadata\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-huggingface==0.1.2) (0.21.1)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface==0.1.2)\n",
      "  Obtaining dependency information for transformers>=4.39.0 from https://files.pythonhosted.org/packages/a9/b6/5257d04ae327b44db31f15cce39e6020cc986333c715660b1315a9724d82/transformers-4.51.3-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (4.13.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (2.11.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.15.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (11.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface==0.1.2) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface==0.1.2) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface==0.1.2) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface==0.1.2) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (3.6.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\giho0\\langgraph_main\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface==0.1.2) (1.3.1)\n",
      "Using cached langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Installing collected packages: transformers, sentence-transformers, langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.1.2 sentence-transformers-4.1.0 transformers-4.51.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "pip install langchain-huggingface==0.1.2\n",
    "pip install langgraph==0.2.34\n",
    "pip install gradio==4.44.1\n",
    "!pip install langchain-community==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e1596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adaptive_self_rag\n",
    "ê¸ˆìœµìƒí’ˆ(ì˜ˆ: ì •ê¸°ì˜ˆê¸ˆ, ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ) ê´€ë ¨ ì§ˆì˜ì— ëŒ€í•´:\n",
    "1. ì§ˆë¬¸ ë¼ìš°íŒ… â†’ (ê¸ˆìœµìƒí’ˆ ê´€ë ¨ì´ë©´) ë¬¸ì„œ ê²€ìƒ‰ (ë³‘ë ¬ ì„œë¸Œ ê·¸ë˜í”„) â†’ ë¬¸ì„œ í‰ê°€ â†’ (ì¡°ê±´ë¶€) ì§ˆë¬¸ ì¬ì‘ì„± â†’ ë‹µë³€ ìƒì„±\n",
    "   / (ê¸ˆìœµìƒí’ˆê³¼ ë¬´ê´€í•˜ë©´) LLM fallbackì„ í†µí•´ ë°”ë¡œ ë‹µë³€ ìƒì„±\n",
    "ê·¸ë¦¬ê³  ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆ(í™˜ê°, ê´€ë ¨ì„±) í‰ê°€ í›„ í•„ìš”ì‹œ ì¬ìƒì„± ë˜ëŠ” ì¬ì‘ì„±í•˜ëŠ” Adaptive Self-RAG ì²´ì¸.\n",
    "\"\"\"\n",
    "\n",
    "#############################\n",
    "# 1. ê¸°ë³¸ í™˜ê²½ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "#############################\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ê¸°íƒ€ ìœ í‹¸\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "from textwrap import dedent\n",
    "from operator import add\n",
    "from heapq import merge\n",
    "from typing import List, Literal, Sequence, TypedDict, Annotated, Tuple\n",
    "\n",
    "# ì„œì¹˜ ì•Œê³ ë¦¬ì¦˜\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# LangChain, Chroma, LLM ê´€ë ¨\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Grader í‰ê°€ì§€í‘œìš©\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# ê·¸ë˜í”„ ê´€ë ¨\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Gradio ê´€ë ¨\n",
    "import gradio as gr\n",
    "\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fece5f9",
   "metadata": {},
   "source": [
    "##### 2. ì„ë² ë”© ë° DBì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ed524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "class LangChainSentenceTransformer(Embeddings):\n",
    "    def __init__(self, model_name: str):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[INFO] Using device: {device}\")\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, show_progress_bar=False, convert_to_numpy=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(text, show_progress_bar=False, convert_to_numpy=True).tolist()\n",
    "\n",
    "embeddings_model_koMultitask = LangChainSentenceTransformer(\"jhgan/ko-sroberta-multitask\") # 768ì°¨ì› ì„ë°°ë”© ëª¨ë¸ë¡œ ë³€ê²½\n",
    "\n",
    "# Chroma DB ê²½ë¡œ\n",
    "CHROMA_DIR = \"./../findata/chroma_db\"\n",
    "\n",
    "# JSON ë°ì´í„° ê²½ë¡œ\n",
    "FIXED_JSON_PATH = \"./../findata/processed_fixed_deposit.json\"\n",
    "DEMAND_JSON_PATH = \"./../findata/processed_demand_deposit.json\"\n",
    "\n",
    "# DB ì´ë¦„\n",
    "FIXED_COLLECTION = \"processed_fixed_deposit\"\n",
    "DEMAND_COLLECTION = \"processed_demand_deposit\"\n",
    "\n",
    "def load_and_prepare_all_documents(json_paths: list[str]) -> list[Document]:\n",
    "    docs: list[Document] = []\n",
    "    for path in json_paths:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        for entry in data[\"documents\"]:\n",
    "            # ë³¸ë¬¸\n",
    "            content = entry[\"content\"]\n",
    "            # metadata í•„ë“œ ì˜ì–´ í‚¤ë¡œ í†µì¼\n",
    "            md = entry.get(\"metadata\", {})\n",
    "            bank         = entry.get(\"bank\",         md.get(\"ì€í–‰\"))\n",
    "            product_name = entry.get(\"product_name\", md.get(\"ìƒí’ˆëª…\"))\n",
    "            category     = entry.get(\"type\")\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\n",
    "                        \"id\":           entry.get(\"id\"),\n",
    "                        \"type\":         category,\n",
    "                        \"bank\":         bank,\n",
    "                        \"product_name\": product_name\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "    return docs\n",
    "\n",
    "# JSON íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "ALL_JSON = [\n",
    "    FIXED_JSON_PATH,\n",
    "    DEMAND_JSON_PATH\n",
    "]\n",
    "\n",
    "all_documents = load_and_prepare_all_documents(ALL_JSON)\n",
    "corpus = [doc.page_content.split() for doc in all_documents]\n",
    "bm25_index = BM25Okapi(corpus)\n",
    "\n",
    "# ì¸ì œìŠ¤ì²œ\n",
    "vector_db = Chroma(\n",
    "    embedding_function=embeddings_model_koMultitask,\n",
    "    collection_name=\"combined_products_koMultitask\",  # ì„ë°°ë”© ëª¨ë¸ì— ë”°ë¥¸ ì¸ì œìŠ¤ì²œ ì´ë¦„ ë³€ê²½\n",
    "    persist_directory=CHROMA_DIR,\n",
    ")\n",
    "\n",
    "# í•œ ë²ˆë§Œ ì¸ì œìŠ¤ì²œ\n",
    "if not vector_db._collection.count():\n",
    "    vector_db.add_documents(all_documents)\n",
    "\n",
    "def extract_bank(query: str) -> str | None:\n",
    "    m = re.search(r'([ê°€-í£A-Za-z0-9]+(?:ì€í–‰|ë±…í¬))', query)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def extract_product(query: str) -> str | None:\n",
    "    # â€œ~í†µì¥â€, â€œ~ì˜ˆê¸ˆâ€, â€œ~ëŒ€ì¶œâ€ ë“±ìœ¼ë¡œ ë§ˆì¹¨\n",
    "    m = re.search(r'([ê°€-í£A-Za-z0-9]+(?:í†µì¥|ì˜ˆê¸ˆ|ëŒ€ì¶œ))', query)\n",
    "    return m.group(1).strip() if m else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f6ba7",
   "metadata": {},
   "source": [
    "##### 3. ì„œì¹˜ì•Œê³ ë¦¬ì¦˜ ë° ë„êµ¬(ê²€ìƒ‰ í•¨ìˆ˜) ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef46902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_with_filters(query: str, filters: dict, top_k: int) -> list[Document]:\n",
    "    # 1) BM25: ì „ì²´ ì½”í¼ìŠ¤ì—ì„œ score ê³„ì‚° â†’ metadata í•„í„° ì ìš©í•´ top_k\n",
    "    tokenized = query.split()\n",
    "    scores = bm25_index.get_scores(tokenized)\n",
    "    idxs   = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    bm25_docs = []\n",
    "    for i in idxs:\n",
    "        d = all_documents[i]\n",
    "        if all(filters.get(k) is None or d.metadata.get(k)==filters[k] for k in filters):\n",
    "            bm25_docs.append(d)\n",
    "            if len(bm25_docs)>=top_k: break\n",
    "\n",
    "    # 2) ë²¡í„°: Chromaì˜ filter íŒŒë¼ë¯¸í„° ì‚¬ìš© (ë‹¨ì¼í‚¤ vs ë‹¤ì¤‘í‚¤ì— ë”°ë¼ $and ë¡œ ë¬¶ì–´ì„œ ì „ë‹¬)\n",
    "    meta = {k: v for k, v in filters.items() if v is not None}\n",
    "    if not meta:\n",
    "        vec_docs = vector_db.similarity_search(query, k=top_k)\n",
    "    elif len(meta) == 1:\n",
    "        # ë‹¨ì¼ í•„í„°í„°\n",
    "        vec_docs = vector_db.similarity_search(query, k=top_k, filter=meta)\n",
    "    else:\n",
    "        # ì—¬ëŸ¬ í•„í„°ëŠ” í•˜ë‚˜ì˜ ì—°ì‚°ì($and)ë¡œ ë¬¶ì–´ì„œ ë„˜ê²¨ì•¼ í•¨\n",
    "        and_list = [{k: v} for k, v in meta.items()]\n",
    "        vec_docs = vector_db.similarity_search(\n",
    "                    query, \n",
    "                    k=top_k, \n",
    "                    filter={\"$and\": and_list}\n",
    "        )\n",
    "\n",
    "    # 3) ì¤‘ë³µ ì œê±° ë° PDF ë§í¬ ì¶”ê°€ ì²˜ë¦¬\n",
    "    seen, merged = set(), []\n",
    "    for d in bm25_docs + vec_docs:\n",
    "        uid = d.metadata[\"id\"]\n",
    "        if uid not in seen:\n",
    "            seen.add(uid)\n",
    "            # PDF ë§í¬ê°€ ìˆìœ¼ë©´ page_contentì— ì¶”ê°€\n",
    "            pdf = d.metadata.get(\"pdf_link\")\n",
    "            if pdf and \"pdf_link\" not in d.page_content:\n",
    "                d.page_content += f\"\\n\\nğŸ“„ [ìƒí’ˆì„¤ëª…ì„œ PDF ë³´ê¸°]({pdf})\"\n",
    "            merged.append(d)\n",
    "    return merged\n",
    "\n",
    "# í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ ì•Œê³ ë¦¬ì¦˜\n",
    "def hybrid_core_search(query: str, category: str, bank: str=None, product_name: str=None, top_k: int=2) -> List[Document]:\n",
    "    # 1) ë©”íƒ€ í•„í„° ì¤€ë¹„ (category í•„ìˆ˜ í¬í•¨)\n",
    "    filters = {\"type\": category}\n",
    "    if bank: \n",
    "        filters[\"bank\"] = bank\n",
    "    if product_name: \n",
    "        filters[\"product_name\"] = product_name\n",
    "\n",
    "    # 2) í•„í„° ë ˆë²¨ë³„ë¡œ ì ì§„ì  ê²€ìƒ‰\n",
    "    filter_levels = [\n",
    "        filters,\n",
    "        {**filters, **{\"product_name\": None}},  # ìƒí’ˆëª… ì œì™¸\n",
    "        {**filters, **{\"bank\": None}},          # ì€í–‰ ì œì™¸\n",
    "        {\"category\": category}                  # ì¹´í…Œê³ ë¦¬ë§Œ\n",
    "    ]\n",
    "\n",
    "    # 3) ìˆœì„œëŒ€ë¡œ BM25+ë²¡í„° ë³‘ë ¬ ê²€ìƒ‰ â†’ ê²°ê³¼ ë°˜í™˜\n",
    "    for flt in filter_levels:\n",
    "        docs = _search_with_filters(query, flt, top_k=top_k)\n",
    "        if docs:\n",
    "            return docs\n",
    "    return []\n",
    "\n",
    "@tool\n",
    "def search_fixed_deposit(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Search for relevant fixed deposit (ì •ê¸°ì˜ˆê¸ˆ) product information using semantic similarity.\n",
    "    This tool retrieves products matching the user's query, such as interest rates or terms.\n",
    "    \"\"\"\n",
    "    bank, product = extract_bank(query), extract_product(query)\n",
    "    return hybrid_core_search(query, category=\"ì •ê¸°ì˜ˆê¸ˆ\", bank=bank, product_name=product)\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_demand_deposit(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Search for demand deposit (ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ) product information using semantic similarity.\n",
    "    This tool retrieves products matching the user's query, such as flexible withdrawal or interest features.\n",
    "    \"\"\"\n",
    "    bank, product = extract_bank(query), extract_product(query)\n",
    "    return hybrid_core_search(query, category=\"ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ\", bank=bank, product_name=product)\n",
    "\n",
    "@tool\n",
    "def web_search(query: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    This tool serves as a supplementary utility for the financial product recommendation model.\n",
    "    It retrieves up-to-date external information via web search using the Tavily API, \n",
    "    especially when relevant data is not available in the local vector databases\n",
    "\n",
    "    Unlike the RAG-based tools that query embedded product databases,\n",
    "    this tool is designed to handle broader or real-time questionsâ€”such as current interest rates, financial trends,\n",
    "    or general queries outside the scope of structured deposit data.\n",
    "\n",
    "    It returns the top 2 semantically relevant documents from the web.\n",
    "    \"\"\"\n",
    "\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        formatted_docs.append(\n",
    "            Document(\n",
    "                page_content= f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>',\n",
    "                metadata={\"source\": \"web search\", \"url\": doc[\"url\"]}\n",
    "                )\n",
    "        )\n",
    "\n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return [Document(page_content=\"ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")]\n",
    "\n",
    "\n",
    "tools = [search_fixed_deposit, search_demand_deposit, web_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff8277",
   "metadata": {},
   "source": [
    "##### 4. llmì´ˆê¸°í™” & ë„êµ¬ ë°”ì¸ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbaf7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39bb28",
   "metadata": {},
   "source": [
    "##### 5. LLM ì²´ì¸ (Retrieval Grader / Answer Generator / Hallucination / Answer Graders / Question Re-writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f85bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================\n",
      " \n",
      "LLM ì²´ì¸\n",
      "\n",
      "# (1) Retrieval Grader\n",
      "\n",
      "\n",
      "# (3) Hallucination Grader\n",
      "\n",
      "\n",
      "# (4) Answer Grader\n",
      "\n",
      "\n",
      "# (5) Question Re-writer\n",
      "\n",
      "\n",
      "# (6) Generation Evaluation & Decision Nodes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# 5. LLM ì²´ì¸ (Retrieval Grader / Answer Generator / Hallucination / Answer Graders / Question Re-writer)\n",
    "#############################\n",
    "print(\"\\n===================================================================\\n \")\n",
    "print(\"LLM ì²´ì¸\\n\")\n",
    "print(\"# (1) Retrieval Grader\\n\")\n",
    "\n",
    "# (1) Retrieval Grader (ê²€ìƒ‰í‰ê°€)\n",
    "class BinaryGradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_BinaryGradeDocuments = llm.with_structured_output(BinaryGradeDocuments)\n",
    "\n",
    "system_prompt = \"\"\"You are an expert in evaluating the relevance of search results to user queries.\n",
    "\n",
    "[Evaluation criteria]\n",
    "1. í‚¤ì›Œë“œ ê´€ë ¨ì„±: ë¬¸ì„œê°€ ì§ˆë¬¸ì˜ ì£¼ìš” ë‹¨ì–´ë‚˜ ìœ ì‚¬ì–´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸\n",
    "2. ì˜ë¯¸ì  ê´€ë ¨ì„±: ë¬¸ì„œì˜ ì „ë°˜ì ì¸ ì£¼ì œê°€ ì§ˆë¬¸ì˜ ì˜ë„ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€\n",
    "3. ë¶€ë¶„ ê´€ë ¨ì„±: ì§ˆë¬¸ì˜ ì¼ë¶€ë¥¼ ë‹¤ë£¨ê±°ë‚˜ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë¬¸ì„œë„ ê³ ë ¤\n",
    "4. ë‹µë³€ ê°€ëŠ¥ì„±: ì§ì ‘ì ì¸ ë‹µì´ ì•„ë‹ˆë”ë¼ë„ ë‹µë³€ í˜•ì„±ì— ë„ì›€ë  ì •ë³´ í¬í•¨ ì—¬ë¶€ í‰ê°€\n",
    "\n",
    "[Scoring]\n",
    "- Rate 'yes' if relevant, 'no' if not\n",
    "- Default to 'no' when uncertain\n",
    "\n",
    "[Key points]\n",
    "- Consider the full context of the query, not just word matching\n",
    "- Rate as relevant if useful information is present, even if not a complete answer\n",
    "\n",
    "Your evaluation is crucial for improving information retrieval systems. Provide balanced assessments.\n",
    "\"\"\"\n",
    "# ì±„ì  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"[Retrieved document]\\n{document}\\n\\n[User question]\\n{question}\")\n",
    "])\n",
    "\n",
    "retrieval_grader_binary = grade_prompt | structured_llm_BinaryGradeDocuments\n",
    "\n",
    "# question = \"ì–´ë–¤ ì˜ˆê¸ˆ ìƒí’ˆì´ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "# print(f'\\nquestion : {question}\\n')\n",
    "# retrieved_docs = fixed_deposit_db.similarity_search(question, k=2)\n",
    "# print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}\")\n",
    "# print(\"===============================================================================\")\n",
    "# print()\n",
    "\n",
    "# relevant_docs = []\n",
    "# for doc in retrieved_docs:\n",
    "#     print(\"ë¬¸ì„œ:\\n\", doc.page_content)\n",
    "#     print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "#     relevance = retrieval_grader_binary.invoke({\"question\": question, \"document\": doc.page_content})\n",
    "#     print(f\"ë¬¸ì„œ ê´€ë ¨ì„±: {relevance}\")\n",
    "\n",
    "#     if relevance.binary_score == 'yes':\n",
    "#         relevant_docs.append(doc)\n",
    "    \n",
    "#     print(\"===========================================================================\")\n",
    "\n",
    "\n",
    "# (2) Answer Generator (ì¼ë°˜ RAG)\n",
    "\n",
    "# (3) Hallucination Grader\n",
    "print(\"\\n# (3) Hallucination Grader\\n\")\n",
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_HradeHallucinations = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# í™˜ê° í‰ê°€ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "halluci_system_prompt = \"\"\"\n",
    "You are an expert evaluator assessing whether an LLM-generated answer is grounded in and supported by a given set of facts.\n",
    "\n",
    "[Your task]\n",
    "    - Review the LLM-generated answer.\n",
    "    - Determine if the answer is fully supported by the given facts.\n",
    "\n",
    "[Evaluation criteria]\n",
    "    - ë‹µë³€ì— ì£¼ì–´ì§„ ì‚¬ì‹¤ì´ë‚˜ ëª…í™•íˆ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì™¸ì˜ ë‚´ìš©ì´ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ë‹µë³€ì˜ ëª¨ë“  í•µì‹¬ ë‚´ìš©ì´ ì£¼ì–´ì§„ ì‚¬ì‹¤ì—ì„œ ë¹„ë¡¯ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ì‚¬ì‹¤ì  ì •í™•ì„±ì— ì§‘ì¤‘í•˜ê³ , ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼ì´ë‚˜ ì™„ì „ì„±ì€ í‰ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "[Scoring]\n",
    "    - 'yes': The answer is factually grounded and fully supported.\n",
    "    - 'no': The answer includes information or claims not based on the given facts.\n",
    "\n",
    "Your evaluation is crucial in ensuring the reliability and factual accuracy of AI-generated responses. Be thorough and critical in your assessment.\n",
    "\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", halluci_system_prompt),\n",
    "        (\"human\", \"[Set of facts]\\n{documents}\\n\\n[LLM generation]\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_HradeHallucinations\n",
    "# hallucination = hallucination_grader.invoke({\"documents\": relevant_docs, \"generation\": generation})\n",
    "# print(f\"í™˜ê° í‰ê°€: {hallucination}\")\n",
    "\n",
    "print(\"\\n# (4) Answer Grader\\n\")\n",
    "# (4) Answer Grader \n",
    "class BinaryGradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_BinaryGradeAnswer = llm.with_structured_output(BinaryGradeAnswer)\n",
    "grade_system_prompt = \"\"\"\n",
    "You are an expert evaluator tasked with assessing whether an LLM-generated answer effectively addresses and resolves a user's question.\n",
    "\n",
    "[Your task]\n",
    "    - Carefully analyze the user's question to understand its core intent and requirements.\n",
    "    - Determine if the LLM-generated answer sufficiently resolves the question.\n",
    "\n",
    "[Evaluation criteria]\n",
    "    - ê´€ë ¨ì„±: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ì™„ì „ì„±: ì§ˆë¬¸ì˜ ëª¨ë“  ì¸¡ë©´ì´ ë‹¤ë¤„ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ì •í™•ì„±: ì œê³µëœ ì •ë³´ê°€ ì •í™•í•˜ê³  ìµœì‹ ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - ëª…í™•ì„±: ë‹µë³€ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›Œì•¼ í•©ë‹ˆë‹¤.\n",
    "    - êµ¬ì²´ì„±: ì§ˆë¬¸ì˜ ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ” ìƒì„¸í•œ ë‹µë³€ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "[Scoring]\n",
    "    - 'yes': The answer effectively resolves the question.\n",
    "    - 'no': The answer fails to sufficiently resolve the question or lacks crucial elements.\n",
    "\n",
    "Your evaluation plays a critical role in ensuring the quality and effectiveness of AI-generated responses. Strive for balanced and thoughtful assessments.\n",
    "\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grade_system_prompt),\n",
    "        (\"human\", \"[User question]\\n{question}\\n\\n[LLM generation]\\n{generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader_binary = answer_prompt | structured_llm_BinaryGradeAnswer\n",
    "# print(\"Question:\", question)\n",
    "# print(\"Generation:\", generation)\n",
    "# answer_score = answer_grader_binary.invoke({\"question\": question, \"generation\": generation})\n",
    "# print(f\"ë‹µë³€ í‰ê°€: {answer_score}\")\n",
    "\n",
    "\n",
    "print(\"\\n# (5) Question Re-writer\\n\")\n",
    "# (5) Question Re-writer\n",
    "def rewrite_question(question: str) -> str:\n",
    "    \"\"\"\n",
    "    ì…ë ¥ ì§ˆë¬¸ì„ ë²¡í„° ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì¬ì‘ì„±í•œë‹¤.\n",
    "    \"\"\"\n",
    "    local_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert question re-writer. Your task is to convert input questions into optimized versions \n",
    "    for vectorstore retrieval. Analyze the input carefully and focus on capturing the underlying semantic \n",
    "    intent and meaning. Your goal is to create a question that will lead to more effective and relevant \n",
    "    document retrieval.\n",
    "\n",
    "    [Guidelines]\n",
    "        1. Identify and emphasize core concepts and key subjects.\n",
    "        2. Expand abbreviations or ambiguous terms.\n",
    "        3. Include synonyms or related terms that might appear in relevant documents.\n",
    "        4. Maintain the original intent and scope.\n",
    "        5. For complex questions, break them down into simpler, focused sub-questions.\n",
    "    \"\"\"\n",
    "    re_write_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"[Initial question]\\n{question}\\n\\n[Improved question]\\n\")\n",
    "    ])\n",
    "    question_rewriter = re_write_prompt | local_llm | StrOutputParser()\n",
    "    rewritten_question = question_rewriter.invoke({\"question\": question})\n",
    "    return rewritten_question\n",
    "\n",
    "print(\"\\n# (6) Generation Evaluation & Decision Nodes\\n\")\n",
    "# (6) Generation Evaluation & Decision Nodes\n",
    "def grade_generation_self(state: \"SelfRagOverallState\") -> str:\n",
    "    print(\"--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\")\n",
    "    print(f\"--- ìƒì„±ëœ ë‹µë³€: {state['generation']} ---\")\n",
    "    if state['num_generations'] > 2:\n",
    "        print(\"--- ìƒì„± íšŸìˆ˜ ì´ˆê³¼, ì¢…ë£Œ -> end ---\")\n",
    "        return \"end\"\n",
    "    # í‰ê°€ë¥¼ ìœ„í•œ ë¬¸ì„œ í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    print(\"--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\")\n",
    "    docs_text = \"\\n\\n\".join([d.page_content for d in state['documents']])\n",
    "    hallucination_grade = hallucination_grader.invoke({\n",
    "        \"documents\": docs_text,\n",
    "        \"generation\": state['generation']\n",
    "    })\n",
    "    if hallucination_grade.binary_score == \"yes\":\n",
    "        relevance_grade = retrieval_grader_binary.invoke({\n",
    "            \"question\": state['question'],\n",
    "            \"document\": state['filtered_documents'],\n",
    "            \"generation\": state['generation']\n",
    "        })\n",
    "        print(\"--- ë‹µë³€-ì§ˆë¬¸ ê´€ë ¨ì„± í‰ê°€ ---\")\n",
    "        if relevance_grade.binary_score == \"yes\":\n",
    "            print(\"--- ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì„ ì˜ í•´ê²°í•¨ ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"--- ë‹µë³€ ê´€ë ¨ì„±ì´ ë¶€ì¡± -> transform_query ---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\")\n",
    "        return \"not supported\"\n",
    "    \n",
    "def decide_to_generate_self(state: \"SelfRagOverallState\") -> str:\n",
    "    print(\"--- í‰ê°€ëœ ë¬¸ì„œ ë¶„ì„ ---\")\n",
    "    if state['num_generations'] > 1:\n",
    "        print(\"--- ìƒì„± íšŸìˆ˜ ì´ˆê³¼, ìƒì„± ê²°ì • ---\")\n",
    "        return \"generate\"\n",
    "    # ì—¬ê¸°ì„œëŠ” í•„í„°ë§ëœ ë¬¸ì„œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if not state['filtered_documents']:\n",
    "        print(\"--- ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ -> transform_query ---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"--- ê´€ë ¨ ë¬¸ì„œ ì¡´ì¬ -> generate ---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# (7) RoutingDecision \n",
    "class RoutingDecision(BaseModel):\n",
    "    \"\"\"Determines whether a user question should be routed to document search or LLM fallback.\"\"\"\n",
    "    route: Literal[\"search_data\",\"llm_fallback\"] = Field(\n",
    "        description=\"Classify the question as 'search_data' (financial) or 'llm_fallback' (general)\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec1e26",
   "metadata": {},
   "source": [
    "##### 6. ìƒíƒœ ì •ì˜ ë° ë…¸ë“œ í•¨ìˆ˜ (ì „ì²´ Adaptive ì²´ì¸)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29163d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ í†µí•©: SelfRagOverallState (ì§ˆë¬¸, ìƒì„±, ì›ë³¸ ë¬¸ì„œ, í•„í„° ë¬¸ì„œ, ìƒì„± íšŸìˆ˜)\n",
    "#TODO\n",
    "\n",
    "# ë©”ì¸ ê·¸ë˜í”„ ìƒíƒœ ì •ì˜\n",
    "class SelfRagOverallState(TypedDict):\n",
    "    \"\"\"\n",
    "    Adaptive Self-RAG ì²´ì¸ì˜ ì „ì²´ ìƒíƒœë¥¼ ê´€ë¦¬    \n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: Annotated[List[str], add]\n",
    "    routing_decision: str \n",
    "    num_generations: int\n",
    "    documents: List[Document]\n",
    "    filtered_documents: List[Document]\n",
    "    history: List[Tuple[str,str]] # (user, bot) ë©”ì‹œì§€ ìŒ ì €ì¥ìš©\n",
    "\n",
    "def initialize_state() -> SelfRagOverallState:\n",
    "    \"\"\"Create a new state with proper initialization of all fields\"\"\"\n",
    "    return {\n",
    "        \"question\": \"\",\n",
    "        \"generation\": [],\n",
    "        \"routing_decision\": \"\",\n",
    "        \"num_generations\": 0,\n",
    "        \"documents\": [],\n",
    "        \"filtered_documents\": [],\n",
    "        \"history\": []\n",
    "    }    \n",
    "# ìƒˆë¡œìš´ ì¬ì‘ì„± ì „ìš© LLM ì²´ì¸ - íˆìŠ¤í† ë¦¬ ë‹µë³€ì´ ìˆëŠ” ê²½ìš° ì´ì „ ëŒ€í™” ë§¥ë½ì— ë§ê²Œ ì§ˆë¬¸ì„ ìˆ˜ì •í•˜ì—¬ ë¬¸ì„œ ì„œì¹˜í•˜ê¸° ìœ„í•¨\n",
    "def contextualize_query(state: SelfRagOverallState) -> dict:\n",
    "    # ìµœê·¼ 3í„´ íˆìŠ¤í† ë¦¬ ì¶”ì¶œ\n",
    "    recent = state['history'][-3:]\n",
    "    hist_block = \"\\n\".join(f\"User: {u}\\nAssistant: {a}\" for u,a in recent)\n",
    "    payload = {\"history\": hist_block, \"question\": state['question']}\n",
    "    improved = question_rewriter_chain.invoke(payload)\n",
    "    return {\"question\": improved}\n",
    "\n",
    "rewrite_input = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ìƒí’ˆ ì±—ë´‡ AIì™€ ìœ ì €ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì§€ë§‰ ìœ ì €ì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê¸ˆìœµìƒí’ˆ ì¶”ì²œ RAG ì‹œìŠ¤í…œì´ ë¬¸ì„œë¥¼ ì˜ ì°¾ì„ ìˆ˜ ìˆê²Œ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”.\"\n",
    "    \"ì¬ì‘ì„±ëœ ì§ˆë¬¸ì€ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ í•˜ë©°, ìœ ì €ê°€ ì›íˆëŠ” í•µì‹¬ì´ ë¬´ì—‡ì¸ì§€ ëª…í™•í•˜ê²Œ ë“¤ì–´ë‚˜ëŠ” ë¬¸ìì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "    \"ì ìš©ë˜ëŠ” RAGì˜ ì„œì¹˜ì•Œê³ ë¦¬ì¦˜ì€ ë°±í„°ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•˜ì„¸ìš”.\"\n",
    "    \"ë§Œì•½ [History]ì— ì•„ë¬´ê²ƒë„ ì—†ê±°ë‚˜ ìœ ì €ì˜ ë§ˆì§€ë§‰ ì§ˆì˜ê°€ ë§¥ë½ìƒ ê¸ˆìœµìƒí’ˆê³¼ ê´€ë ¨ëœ ê²ƒì´ ì•„ë‹ˆë¼ë©´ ìœ ì €ì˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”.\"),\n",
    "    (\"system\", \"[History]\\n{history}\"),\n",
    "    (\"human\", \"[Question]\\n{question}\\n\\n[Improved Question]\\n\"),\n",
    "])\n",
    "question_rewriter_chain = rewrite_input | llm | StrOutputParser()\n",
    "\n",
    "# ì§ˆë¬¸ ì¬ì‘ì„± ë…¸ë“œ (ë³€ê²½ í›„ ê²€ìƒ‰ ë£¨í”„)\n",
    "def transform_query_self(state: SelfRagOverallState) -> dict:\n",
    "    print(\"--- ì§ˆë¬¸ ê°œì„  ---\")\n",
    "    new_question = rewrite_question(state['question'])\n",
    "    print(f\"--- ê°œì„ ëœ ì§ˆë¬¸ : \\n{new_question} \")\n",
    "    new_count = state['num_generations'] + 1\n",
    "    print(f\"num_generations : {new_count}\")\n",
    "    return {\"question\": new_question, \"num_generations\": new_count}\n",
    "\n",
    "# ë‹µë³€ ìƒì„± ë…¸ë“œ (ì„œë¸Œ ê·¸ë˜í”„ë¡œë¶€í„° ë°›ì€ í•„í„° ë¬¸ì„œ ìš°ì„  ì‚¬ìš©, ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³  í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •)\n",
    "def format_chat_history(history):\n",
    "    messages = []\n",
    "    for user_msg, assistant_msg in history:\n",
    "        messages.append((\"human\", user_msg))\n",
    "        messages.append((\"ai\", assistant_msg))\n",
    "    return messages\n",
    "\n",
    "generate_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"\n",
    "[Your task]\n",
    "You are a financial product expert and consultant who always responds in Korean.\n",
    "Analyze the user query and the given financial product data to recommend the most suitable product.\n",
    "Use the conversation history to maintain context. Rely only on the provided documents and history.\n",
    "\n",
    "[Instructions]\n",
    "1. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ë¬¸ë§¥ì—ì„œ ì‹ ì¤‘í•˜ê²Œ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "2. ë‹µë³€ì— ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ì •ë³´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "3. ë¬¸ë§¥ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì— ëŒ€í•´ ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "4. ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ í”¼í•˜ê³ , ëª…í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "5. ë¬¸ë§¥ì—ì„œ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ë‹¤ë©´ ë§ˆì§€ë§‰ì— \"ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.     \n",
    "\"\"\".strip()),\n",
    "    (\"system\", \"[Context]\\n{context}\"),\n",
    "    (\"system\", \"[History]\\n{formatted_history}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def generate_self(state: SelfRagOverallState) -> dict:\n",
    "    print(\"--- ë‹µë³€ ìƒì„± (íˆìŠ¤í† ë¦¬ í¬í•¨) ---\")\n",
    "    \n",
    "    # ìµœê·¼ ëŒ€í™” ì œí•œ\n",
    "    recent_history = state[\"history\"][10:] if len(state[\"history\"]) > 5 else state[\"history\"][:5]\n",
    "\n",
    "    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…\n",
    "    formatted_history = \"\"\n",
    "    for user_msg, assistant_msg in recent_history:\n",
    "        formatted_history += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
    "\n",
    "    # 2) context ì§ë ¬í™”\n",
    "    docs = state['filtered_documents'] or state['documents']\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs) if docs else \"ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ\"\n",
    "\n",
    "    # 3) í”„ë¡¬í”„íŠ¸ì— ê°’ ë„£ê³  LLM í˜¸ì¶œ\n",
    "    chain = generate_template  | llm | StrOutputParser()\n",
    "    out = chain.invoke({\n",
    "        \"formatted_history\": formatted_history,\n",
    "        \"context\": context,\n",
    "        \"question\": state[\"question\"],\n",
    "    })\n",
    "    answer: str = out\n",
    "\n",
    "    # 4) ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "    state[\"num_generations\"] += 1\n",
    "    state[\"generation\"] = answer\n",
    "\n",
    "    return {\n",
    "        \"generation\": [answer],\n",
    "        \"num_generations\": state[\"num_generations\"],\n",
    "    }\n",
    "\n",
    "\n",
    "structured_llm_RoutingDecision = llm.with_structured_output(RoutingDecision)\n",
    "\n",
    "question_router_system  = \"\"\"\n",
    "You are an AI assistant that routes user questions to the appropriate processing path.\n",
    "Return one of the following labels:\n",
    "- search_data\n",
    "- llm_fallback\n",
    "\"\"\"\n",
    "\n",
    "question_router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", question_router_system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "question_router = question_router_prompt | structured_llm_RoutingDecision\n",
    "\n",
    "# question route ë…¸ë“œ \n",
    "def route_question_adaptive(state: SelfRagOverallState) -> dict:\n",
    "    print(\"--- ì§ˆë¬¸ íŒë‹¨ (ì¼ë°˜ or ê¸ˆìœµ) ---\")\n",
    "    print(f\"ì§ˆë¬¸: {state['question']}\")\n",
    "    decision = question_router.invoke({\"question\": state['question']})\n",
    "    print(\"routing_decision:\", decision.route)\n",
    "    return {\"routing_decision\": decision.route}\n",
    "\n",
    "# question route ë¶„ê¸° í•¨ìˆ˜ \n",
    "def route_question_adaptive_self(state: SelfRagOverallState) -> str:\n",
    "    \"\"\"\n",
    "    ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ 'ê¸ˆìœµì§ˆë¬¸'ì¸ì§€ 'ì¼ë°˜ì§ˆë¬¸'ì¸ì§€ íŒë‹¨\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if state['routing_decision'] == \"llm_fallback\":\n",
    "            print(\"--- ì¼ë°˜ì§ˆë¬¸ìœ¼ë¡œ ë¼ìš°íŒ… ---\")\n",
    "            return \"llm_fallback\"\n",
    "        else:\n",
    "            print(\"--- ê¸ˆìœµì§ˆë¬¸ìœ¼ë¡œ ë¼ìš°íŒ… ---\")\n",
    "            return \"search_data\"\n",
    "    except Exception as e:\n",
    "        print(f\"--- ì§ˆë¬¸ ë¶„ì„ ì¤‘ Exception ë°œìƒ: {e} ---\")\n",
    "        return \"llm_fallback\"\n",
    "\n",
    "\n",
    "fallback_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    You are an AI assistant helping with various topics. \n",
    "    Respond in Korean.\n",
    "    - Provide accurate and helpful information.\n",
    "    - Keep answers concise yet informative.\n",
    "    - Inform users they can ask for clarification if needed.\n",
    "    - Let users know they can ask follow-up questions if needed.\n",
    "    - End every answer with the sentence: \"ì €ëŠ” ê¸ˆìœµìƒí’ˆ ì§ˆë¬¸ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµìƒí’ˆê´€ë ¨ ì§ˆë¬¸ì„ ì£¼ì„¸ìš”.\"\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def llm_fallback_adaptive(state: SelfRagOverallState) -> dict:\n",
    "    \"\"\"Generates a direct response using the LLM when the question is unrelated to financial products.\"\"\"\n",
    "    print(\"--- ì¼ë°˜ ì§ˆë¬¸ Fallback (íˆìŠ¤í† ë¦¬ ë°˜ì˜) ---\")\n",
    "    \n",
    "    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…\n",
    "    formatted_history = \"\"\n",
    "    for user_msg, assistant_msg in state[\"history\"]:\n",
    "        formatted_history += f\"User: {user_msg}\\nAssistant: {assistant_msg}\\n\\n\"\n",
    "\n",
    "\n",
    "    fallback_chain = fallback_prompt | llm | StrOutputParser()\n",
    "    out = fallback_chain.invoke({\n",
    "        \"formatted_history\": formatted_history,\n",
    "        \"question\": state[\"question\"],\n",
    "    })\n",
    "    answer: str = out\n",
    "\n",
    "    state[\"history\"].append((state[\"question\"], answer))\n",
    "    return {\"generation\": [answer]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2de9f1",
   "metadata": {},
   "source": [
    "##### 7. [ì„œë¸Œ ê·¸ë˜í”„ í†µí•©] - ë³‘ë ¬ ê²€ìƒ‰ ì„œë¸Œ ê·¸ë˜í”„ êµ¬í˜„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0921400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ìƒíƒœ ì •ì˜ (ê²€ìƒ‰ ì„œë¸Œ ê·¸ë˜í”„ ì „ìš©) ---\n",
    "class SearchState(TypedDict):\n",
    "    question: str\n",
    "    # generation: str\n",
    "    documents: Annotated[List[Document], add]  # íŒ¬ì•„ì›ƒëœ ê° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëˆ„ì í•  ê²ƒ\n",
    "    filtered_documents: List[Document]         # ê´€ë ¨ì„± í‰ê°€ë¥¼ í†µê³¼í•œ ë¬¸ì„œë“¤\n",
    "\n",
    "# ToolSearchState: SearchStateì— ì¶”ê°€ ì •ë³´(datasources) í¬í•¨\n",
    "class ToolSearchState(SearchState):\n",
    "    datasources: List[str]  # ì°¸ì¡°í•  ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡\n",
    "\n",
    "# --- ì„œë¸Œê·¸ë˜í”„ ë…¸ë“œ í•¨ìˆ˜ ---\n",
    "def search_fixed_deposit_node(state: SearchState):\n",
    "    \"\"\"\n",
    "    ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ê²€ìƒ‰ (ì„œë¸Œ ê·¸ë˜í”„)\n",
    "    \"\"\"\n",
    "    docs = search_fixed_deposit.invoke(state[\"question\"])\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "def search_demand_deposit_node(state: SearchState):\n",
    "    \"\"\"\n",
    "    ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ ìƒí’ˆ ê²€ìƒ‰ (ì„œë¸Œ ê·¸ë˜í”„)\n",
    "    \"\"\"\n",
    "    docs = search_demand_deposit.invoke(state[\"question\"])\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "def filter_documents_subgraph(state: SearchState):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì— ëŒ€í•´ ê´€ë ¨ì„± í‰ê°€ í›„ í•„í„°ë§\n",
    "    \"\"\"\n",
    "    print(\"--- ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (ì„œë¸Œ ê·¸ë˜í”„) ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader_binary.invoke({\n",
    "            \"question\": question,\n",
    "            \"document\": d.page_content\n",
    "        })\n",
    "        if score.binary_score == \"yes\":\n",
    "            print(\"--- ë¬¸ì„œ ê´€ë ¨ì„±: ìˆìŒ ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- ë¬¸ì„œ ê´€ë ¨ì„±: ì—†ìŒ ---\")\n",
    "    return {\"filtered_documents\": filtered_docs}\n",
    "\n",
    "def search_web_search_subgraph(state: SearchState):\n",
    "    \"\"\"\n",
    "    ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ê¸ˆìœµ ì •ë³´ ê²€ìƒ‰ (ì„œë¸Œ ê·¸ë˜í”„)\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    print('--- ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ---')\n",
    "\n",
    "    docs = web_search.invoke({\"query\": question})  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë„˜ê¹€\n",
    "\n",
    "    if len(docs) > 0:\n",
    "        return {\"documents\": docs}\n",
    "    else:\n",
    "        return {\"documents\": [Document(page_content=\"ê´€ë ¨ ì›¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")]}\n",
    "\n",
    "# --- ì§ˆë¬¸ ë¼ìš°íŒ… (ì„œë¸Œ ê·¸ë˜í”„ ì „ìš©) ---\n",
    "class SubgraphToolSelector(BaseModel):\n",
    "    \"\"\"Selects the most appropriate tool for the user's question.\"\"\"\n",
    "    tool: Literal[\"search_fixed_deposit\", \"search_demand_deposit\", \"web_search\"] = Field(\n",
    "        description=\"Select one of the tools: search_fixed_deposit, search_demand_deposit or web_search based on the user's question.\"\n",
    "    )\n",
    "\n",
    "class SubgraphToolSelectors(BaseModel):\n",
    "    \"\"\"Selects all tools relevant to the user's question.\"\"\"\n",
    "    tools: List[SubgraphToolSelector] = Field(\n",
    "        description=\"Select one or more tools: search_fixed_deposit, search_demand_deposit or web_search based on the user's question.\"\n",
    "    )\n",
    "\n",
    "structured_llm_SubgraphToolSelectors = llm.with_structured_output(SubgraphToolSelectors)\n",
    "\n",
    "subgraph_system  = dedent(\"\"\"\\\n",
    "You are an AI assistant specializing in routing user questions to the appropriate tools.\n",
    "Use the following guidelines:\n",
    "- For fixed deposit product queries, use the search_fixed_deposit tool.\n",
    "- For demand deposit product queries, use the search_demand_deposit tool.\n",
    "- For general financial or real-time information queries, or when the user explicitly mentions 'web search',\n",
    "  use the web_search tool.\n",
    "  Always choose the appropriate tools based on the user's question.\n",
    "\"\"\")\n",
    "subgraph_route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", subgraph_system),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "question_tool_router = subgraph_route_prompt  | structured_llm_SubgraphToolSelectors\n",
    "\n",
    "def analyze_question_tool_search(state: ToolSearchState):\n",
    "    \"\"\"\n",
    "    ì§ˆë¬¸ ë¶„ì„ ë° ë¼ìš°íŒ…: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì°¸ì¡°í•  ë°ì´í„° ì†ŒìŠ¤ ê²°ì •\n",
    "    \"\"\"\n",
    "    print(\"--- ì§ˆë¬¸ ë¼ìš°íŒ… ---\")\n",
    "    question = state[\"question\"]\n",
    "    result = question_tool_router.invoke({\"question\": question})\n",
    "    datasources = [tool.tool for tool in result.tools]\n",
    "    return {\"datasources\": datasources}\n",
    "\n",
    "def route_datasources_tool_search(state: ToolSearchState) -> Sequence[str]:\n",
    "    \"\"\"\n",
    "    ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¼ ì‹¤í–‰í•  ê²€ìƒ‰ ë…¸ë“œë¥¼ ê²°ì • (ë³‘ë ¬ë¡œ íŒ¬ì•„ì›ƒ)\n",
    "    \"\"\"\n",
    "    datasources = set(state['datasources'])\n",
    "\n",
    "    # ëª…í™•íˆ í•˜ë‚˜ë§Œ ì„ íƒëœ ê²½ìš°\n",
    "    if datasources == {'search_fixed_deposit'}:\n",
    "        return ['search_fixed_deposit']\n",
    "    elif datasources == {'search_demand_deposit'}:\n",
    "        return ['search_demand_deposit']\n",
    "    elif datasources == {'web_search'}:\n",
    "        return ['web_search']\n",
    "\n",
    "    # ë„êµ¬ê°€ ì „ë¶€ ì‹¤í–‰ë˜ê±°ë‚˜ ì• ë§¤ëª¨í˜¸í•  ë•ŒëŠ” ë„êµ¬ ì „ë¶€ ì‹¤í–‰\n",
    "    return ['search_fixed_deposit', 'search_demand_deposit', 'web_search']\n",
    "\n",
    "\n",
    "# --- ì„œë¸Œ ê·¸ë˜í”„ ë¹Œë” êµ¬ì„± ---\n",
    "search_builder = StateGraph(ToolSearchState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "search_builder.add_node(\"analyze_question\", analyze_question_tool_search)\n",
    "search_builder.add_node(\"search_fixed_deposit\", search_fixed_deposit_node)   # wapper í•¨ìˆ˜ ë§ê³  ì§ì ‘ invoke í•¨ìˆ˜ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ìˆ˜ì •\n",
    "search_builder.add_node(\"search_demand_deposit\", search_demand_deposit_node) # ë§ˆì°¬ê°€ì§€ë¡œ í•¨ê»˜\n",
    "search_builder.add_node(\"web_search\", search_web_search_subgraph)\n",
    "search_builder.add_node(\"filter_documents\", filter_documents_subgraph)\n",
    "\n",
    "# ì—£ì§€ êµ¬ì„±\n",
    "search_builder.add_edge(START, \"analyze_question\")\n",
    "search_builder.add_conditional_edges(\n",
    "    \"analyze_question\",\n",
    "    route_datasources_tool_search,\n",
    "    {\n",
    "        \"search_fixed_deposit\": \"search_fixed_deposit\",\n",
    "        \"search_demand_deposit\": \"search_demand_deposit\",\n",
    "        \"web_search\": \"web_search\"\n",
    "    }\n",
    ")\n",
    "# ë‘ ê²€ìƒ‰ ë…¸ë“œ ëª¨ë‘ ì‹¤í–‰í•œ í›„ ê°ê°ì˜ ê²°ê³¼ëŠ” filter_documentsë¡œ íŒ¬ì¸(fan-in) ì²˜ë¦¬\n",
    "search_builder.add_edge(\"search_fixed_deposit\", \"filter_documents\")\n",
    "search_builder.add_edge(\"search_demand_deposit\", \"filter_documents\")\n",
    "search_builder.add_edge(\"web_search\", \"filter_documents\")\n",
    "search_builder.add_edge(\"filter_documents\", END)\n",
    "\n",
    "# ì„œë¸Œ ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "tool_search_graph = search_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61732ee6",
   "metadata": {},
   "source": [
    "##### 8. [ì „ì²´ ê·¸ë˜í”„ì™€ ê²°í•©] - Self-RAG Overall Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2ed831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ê·¸ë˜í”„ ë¹Œë” (rag_builder) êµ¬ì„±\n",
    "rag_builder = StateGraph(SelfRagOverallState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€: ê²€ìƒ‰ ì„œë¸Œ ê·¸ë˜í”„, ìƒì„±, ì§ˆë¬¸ ì¬ì‘ì„± ë“±\n",
    "rag_builder.add_node(\"contextualize_query\", contextualize_query)\n",
    "rag_builder.add_node(\"route_question\", route_question_adaptive)\n",
    "rag_builder.add_node(\"llm_fallback\", llm_fallback_adaptive)\n",
    "rag_builder.add_node(\"search_data\", tool_search_graph)         # ì„œë¸Œ ê·¸ë˜í”„ë¡œ ë³‘ë ¬ ê²€ìƒ‰ ë° í•„í„°ë§ ìˆ˜í–‰\n",
    "rag_builder.add_node(\"generate\", generate_self)                # ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "rag_builder.add_node(\"transform_query\", transform_query_self)  # ì§ˆë¬¸ ê°œì„  ë…¸ë“œ\n",
    "\n",
    "# ì „ì²´ ê·¸ë˜í”„ ì—£ì§€ êµ¬ì„±\n",
    "rag_builder.add_edge(START, \"contextualize_query\")\n",
    "rag_builder.add_edge(\"contextualize_query\", \"route_question\")\n",
    "rag_builder.add_conditional_edges(\n",
    "    \"route_question\",\n",
    "    route_question_adaptive_self, \n",
    "    {\n",
    "        \"llm_fallback\": \"llm_fallback\",\n",
    "        \"search_data\": \"search_data\"\n",
    "    }\n",
    ")\n",
    "rag_builder.add_edge(\"llm_fallback\", END)\n",
    "rag_builder.add_conditional_edges(\n",
    "    \"search_data\",\n",
    "    decide_to_generate_self, \n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    }\n",
    ")\n",
    "rag_builder.add_edge(\"transform_query\", \"search_data\")\n",
    "rag_builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_self,\n",
    "    {\n",
    "        \"not supported\": \"generate\",      # í™˜ê° ë°œìƒ ì‹œ ì¬ìƒì„±\n",
    "        \"not useful\": \"transform_query\",  # ê´€ë ¨ì„± ë¶€ì¡± ì‹œ ì§ˆë¬¸ ì¬ì‘ì„± í›„ ì¬ê²€ìƒ‰\n",
    "        \"useful\": END,\n",
    "        \"end\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "# MemorySaver ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëŒ€í™” ìƒíƒœë¥¼ ì €ì¥í•  in-memory í‚¤-ê°’ ì €ì¥ì†Œ)\n",
    "memory = MemorySaver()\n",
    "adaptive_self_rag_memory = rag_builder.compile(checkpointer=memory)\n",
    "# adaptive_self_rag = rag_builder.compile()\n",
    "\n",
    "# ê·¸ë˜í”„ íŒŒì¼ ì €ì¥í•˜ê¸°\n",
    "# display(Image(adaptive_self_rag.get_graph().draw_mermaid_png()))\n",
    "with open(\"adaptive_self_rag_memory.mmd\", \"w\") as f:\n",
    "    f.write(adaptive_self_rag_memory.get_graph(xray=True).draw_mermaid()) # ì €ì¥ëœ mmd íŒŒì¼ì—ì„œ ì½”ë“œ ë³µì‚¬ í›„ https://mermaid.live ì— ë¶™ì—¬ë„£ê¸°.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ ë¬¸ì„œ 1\n",
      "ë‚´ìš©: ê²½ì œì§€í‘œ ë‰´ìŠ¤ ì±„ê¶Œ ì±„ê¶Œ ê²½ì œì§€í‘œ ë‰´ìŠ¤ ì±„ê¶Œ 1ì¸ë‹¹ êµ­ë‚´ì´ìƒì‚° ì±„ê¶Œ Apps App Store ê²½ì œì§€í‘œ ë¯¸êµ­ì˜ ê¸°ì¤€ ê¸ˆë¦¬ëŠ” ë§ˆì§€ë§‰ ê¸°ë¡ìœ¼ë¡œ 4.50%ì…ë‹ˆë‹¤. | ì€í–‰ì˜ ëŒ€ì°¨ ëŒ€ì¡°í‘œ | 23964.10 | 23911.30 | USD - ì–µ | Mar 2025 | | ì™¸í™˜ ë³´ìœ ê³  | 35208.00 | 34865.00 | USD - ë°±ë§Œ | Jan 2025 | | Fed Interest Rate | 4.50 | 4.50 | í¼ì„¼íŠ¸ | Mar 2025 | ë‰´ìŠ¤ êµ­ë‚´ ì´ìƒì‚° êµ­ë‚´ ì´ìƒì‚° ê³ ì •ê°€ê²© êµ­ë‚´ì´ìƒì‚° 1ì¸ë‹¹ êµ­ë‚´ì´ìƒì‚° ì±Œë¦°ì € í•´ê³ ì \n",
      "ë©”íƒ€ë°ì´í„°: {'source': 'web_search', 'url': 'https://ko.tradingeconomics.com/united-states/interest-rate'}\n",
      "\n",
      "ğŸ”¹ ë¬¸ì„œ 2\n",
      "ë‚´ìš©: 2025ë…„ 5ì›” ê¸°ì¤€, 24ê°œì›”, 36ê°œì›” ë§Œê¸° ì€í–‰ ì •ê¸°ì˜ˆê¸ˆ ì´ìœ¨ í˜„í™©ì„ ì´ì–´ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì•ì„œ 6~12ê°œì›” ë§Œê¸° ìƒí’ˆì€ ê¸°ë³¸ ì´ìœ¨ ê¸°ì¤€ ì—° 2.50% ì´ìƒì¸\n",
      "\n",
      " ê´€ë ¨ ë§í¬: https://blog.naver.com/rbeod1/223849321321?fromRss=true&trackingCode=rss\n",
      "ë©”íƒ€ë°ì´í„°: {'source': 'web_search', 'url': 'https://blog.naver.com/rbeod1/223849321321?fromRss=true&trackingCode=rss'}\n"
     ]
    }
   ],
   "source": [
    "# # âœ… 1. ì§ˆë¬¸ ì •ì˜\n",
    "# example_state = {\n",
    "#     \"question\": \"2025ë…„ 5ì›” ìµœì‹  ê¸ˆë¦¬ ì •ë³´ë¥¼ web searchë¡œ ì°¾ì•„ì¤˜\"\n",
    "# }\n",
    "\n",
    "# # âœ… 2. íˆ´ ì„ íƒ (LLMì´ íŒë‹¨)\n",
    "# result = question_tool_router.invoke({\"question\": example_state[\"question\"]})\n",
    "\n",
    "# # âœ… 3. ì„ íƒëœ íˆ´ ì¶œë ¥\n",
    "# selected_tools = [tool.tool for tool in result.tools]\n",
    "# print(\"âœ… ì„ íƒëœ ë„êµ¬:\", selected_tools)\n",
    "\n",
    "# # âœ… 4. web_searchê°€ ì„ íƒëì„ ê²½ìš° ì‹¤í–‰\n",
    "# if \"web_search\" in selected_tools:\n",
    "#     print(\"\\nğŸŸ¡ ì‹¤í–‰ ì¤‘: web_search_subgraph\")\n",
    "\n",
    "#     # SearchState êµ¬ì¡°ì™€ ì¼ì¹˜ì‹œì¼œ í˜¸ì¶œ\n",
    "#     search_result = search_web_search_subgraph({\"question\": example_state[\"question\"]})\n",
    "\n",
    "#     print(\"\\nğŸ“„ ì›¹ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "#     for i, doc in enumerate(search_result[\"documents\"], start=1):\n",
    "#         print(f\"\\nğŸ”¹ ê²°ê³¼ {i}\")\n",
    "#         print(\"ë‚´ìš©:\", doc.page_content[:300], \"...\")\n",
    "#         print(\"ë©”íƒ€ë°ì´í„°:\", doc.metadata)\n",
    "\n",
    "# else:\n",
    "#     print(\"âŒ web_searchëŠ” ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3baa60",
   "metadata": {},
   "source": [
    "##### 9. Gradio Chatbot êµ¬ì„± ë° ì‹¤í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fdd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://71841411e2e34a816c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://71841411e2e34a816c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ì§ˆë¬¸ íŒë‹¨ (ì¼ë°˜ or ê¸ˆìœµ) ---\n",
      "ì§ˆë¬¸: êµ­ë¯¼ì€í–‰ì˜ ì…ì¶œê¸ˆ ìƒí’ˆì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ìš”ì²­í•©ë‹ˆë‹¤.\n",
      "routing_decision: search_data\n",
      "--- ê¸ˆìœµì§ˆë¬¸ìœ¼ë¡œ ë¼ìš°íŒ… ---\n",
      "--- ì§ˆë¬¸ ë¼ìš°íŒ… ---\n",
      "--- ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (ì„œë¸Œ ê·¸ë˜í”„) ---\n",
      "--- ë¬¸ì„œ ê´€ë ¨ì„±: ì—†ìŒ ---\n",
      "--- ë¬¸ì„œ ê´€ë ¨ì„±: ì—†ìŒ ---\n",
      "--- ë¬¸ì„œ ê´€ë ¨ì„±: ìˆìŒ ---\n",
      "--- ë¬¸ì„œ ê´€ë ¨ì„±: ì—†ìŒ ---\n",
      "--- í‰ê°€ëœ ë¬¸ì„œ ë¶„ì„ ---\n",
      "--- ê´€ë ¨ ë¬¸ì„œ ì¡´ì¬ -> generate ---\n",
      "--- ë‹µë³€ ìƒì„± (íˆìŠ¤í† ë¦¬ í¬í•¨) ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['êµ­ë¯¼ì€í–‰ì˜ ì…ì¶œê¸ˆ ìƒí’ˆ ì¤‘ í•˜ë‚˜ì¸ KBë§ˆì´í•í†µì¥ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\n\\n- **ìƒí’ˆëª…**: KBë§ˆì´í•í†µì¥\\n- **ê¸°ë³¸ê¸ˆë¦¬**: 0.1%\\n- **ìµœê³ ê¸ˆë¦¬**: 1.5% (ìš°ëŒ€ê¸ˆë¦¬ í¬í•¨)\\n- **ì´ì ì§€ê¸‰ ë°©ì‹**: ë¶„ê¸° ì§€ê¸‰\\n- **ê°€ì… ë°©ë²•**: ì˜ì—…ì  ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ë±…í‚¹ì„ í†µí•´ ê°€ì… ê°€ëŠ¥\\n- **ê°€ì… ëŒ€ìƒ**: ë§Œ 18ì„¸ ì´ìƒ ë§Œ 38ì„¸ ì´í•˜ì˜ ì‹¤ëª…ì˜ ê°œì¸\\n- **ê°€ì… ì œí•œ ì¡°ê±´**: ì œí•œ ì—†ìŒ\\n- **ìš°ëŒ€ ì¡°ê±´**: ì´ì ì§€ê¸‰ ì›”ì˜ ì „ì›” ë§ì¼ ê¸°ì¤€ìœ¼ë¡œ ì§ì „ 3ê°œì›” ë™ì•ˆ ì•„ë˜ì˜ ì…ê¸ˆ ì‹¤ì  ì¤‘ í•œ ê°€ì§€ë¥¼ 2ê°œì›” ì´ìƒ ì¶©ì¡±í•´ì•¼ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì œê³µë©ë‹ˆë‹¤.\\n  1. ê³ ê° ì§€ì •ì¼ì— ê±´ë³„ 50ë§Œì› ì´ìƒ ì…ê¸ˆ\\n  2. ê¸‰ì—¬ì„± ë¬¸êµ¬ê°€ í¬í•¨ëœ ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ì…ê¸ˆ\\n  3. ë‹¹í–‰ ê¸‰ì—¬ì´ì²´ ì „ì‚°ì„ í†µí•´ ì…ê¸ˆë˜ëŠ” ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ê¸‰ì—¬ ì…ê¸ˆ\\n- **ê¸°íƒ€ ìœ ì˜ì‚¬í•­**:\\n  1. í•˜ë‚˜ì˜ í†µì¥ì„ ëª©ì ì— ë§ê²Œ ìª¼ê°œ ì“¸ ìˆ˜ ìˆëŠ” í†µì¥ì…ë‹ˆë‹¤ (ê¸°ë³¸ë¹„/ìƒí™œë¹„/ë¹„ìƒê¸ˆ).\\n  2. ìš°ëŒ€ ì¡°ê±´ì„ ì¶©ì¡±í•  ê²½ìš° ë§¤ì¼ì˜ ë¹„ìƒê¸ˆë°•ìŠ¤ ìµœì¢… ì”ì•¡(ìµœëŒ€ 2ë°±ë§Œì›)ì— ëŒ€í•´ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì ìš©ë©ë‹ˆë‹¤.\\n  3. 1ì¸ 1ê³„ì¢Œë¡œ ì œí•œë©ë‹ˆë‹¤.\\n\\në” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'] ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ë‹µë³€-ì§ˆë¬¸ ê´€ë ¨ì„± í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì„ ì˜ í•´ê²°í•¨ ---\n",
      "--- History í™•ì¸ ---\n",
      "[('êµ­ë¯¼ì€í–‰ ì…ì¶œê¸ˆ ìƒí’ˆì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜ ë§¤ìš° ìì„¸í•˜ê²Œ', 'êµ­ë¯¼ì€í–‰ì˜ ì…ì¶œê¸ˆ ìƒí’ˆ ì¤‘ í•˜ë‚˜ì¸ KBë§ˆì´í•í†µì¥ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\n\\n- **ìƒí’ˆëª…**: KBë§ˆì´í•í†µì¥\\n- **ê¸°ë³¸ê¸ˆë¦¬**: 0.1%\\n- **ìµœê³ ê¸ˆë¦¬**: 1.5% (ìš°ëŒ€ê¸ˆë¦¬ í¬í•¨)\\n- **ì´ì ì§€ê¸‰ ë°©ì‹**: ë¶„ê¸° ì§€ê¸‰\\n- **ê°€ì… ë°©ë²•**: ì˜ì—…ì  ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ë±…í‚¹ì„ í†µí•´ ê°€ì… ê°€ëŠ¥\\n- **ê°€ì… ëŒ€ìƒ**: ë§Œ 18ì„¸ ì´ìƒ ë§Œ 38ì„¸ ì´í•˜ì˜ ì‹¤ëª…ì˜ ê°œì¸\\n- **ê°€ì… ì œí•œ ì¡°ê±´**: ì œí•œ ì—†ìŒ\\n- **ìš°ëŒ€ ì¡°ê±´**: ì´ì ì§€ê¸‰ ì›”ì˜ ì „ì›” ë§ì¼ ê¸°ì¤€ìœ¼ë¡œ ì§ì „ 3ê°œì›” ë™ì•ˆ ì•„ë˜ì˜ ì…ê¸ˆ ì‹¤ì  ì¤‘ í•œ ê°€ì§€ë¥¼ 2ê°œì›” ì´ìƒ ì¶©ì¡±í•´ì•¼ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì œê³µë©ë‹ˆë‹¤.\\n  1. ê³ ê° ì§€ì •ì¼ì— ê±´ë³„ 50ë§Œì› ì´ìƒ ì…ê¸ˆ\\n  2. ê¸‰ì—¬ì„± ë¬¸êµ¬ê°€ í¬í•¨ëœ ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ì…ê¸ˆ\\n  3. ë‹¹í–‰ ê¸‰ì—¬ì´ì²´ ì „ì‚°ì„ í†µí•´ ì…ê¸ˆë˜ëŠ” ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ê¸‰ì—¬ ì…ê¸ˆ\\n- **ê¸°íƒ€ ìœ ì˜ì‚¬í•­**:\\n  1. í•˜ë‚˜ì˜ í†µì¥ì„ ëª©ì ì— ë§ê²Œ ìª¼ê°œ ì“¸ ìˆ˜ ìˆëŠ” í†µì¥ì…ë‹ˆë‹¤ (ê¸°ë³¸ë¹„/ìƒí™œë¹„/ë¹„ìƒê¸ˆ).\\n  2. ìš°ëŒ€ ì¡°ê±´ì„ ì¶©ì¡±í•  ê²½ìš° ë§¤ì¼ì˜ ë¹„ìƒê¸ˆë°•ìŠ¤ ìµœì¢… ì”ì•¡(ìµœëŒ€ 2ë°±ë§Œì›)ì— ëŒ€í•´ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì ìš©ë©ë‹ˆë‹¤.\\n  3. 1ì¸ 1ê³„ì¢Œë¡œ ì œí•œë©ë‹ˆë‹¤.\\n\\në” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')]\n",
      "--- ì§ˆë¬¸ íŒë‹¨ (ì¼ë°˜ or ê¸ˆìœµ) ---\n",
      "ì§ˆë¬¸: ë§ˆì´í•í†µì¥ì— ê°€ì¥ ì í•©í•œ ì‚¬ìš©ì ìœ í˜•ì€ ì–´ë–¤ ì‚¬ëŒë“¤ì¸ê°€ìš”?\n",
      "routing_decision: llm_fallback\n",
      "--- ì¼ë°˜ì§ˆë¬¸ìœ¼ë¡œ ë¼ìš°íŒ… ---\n",
      "--- ì¼ë°˜ ì§ˆë¬¸ Fallback (íˆìŠ¤í† ë¦¬ ë°˜ì˜) ---\n",
      "--- History í™•ì¸ ---\n",
      "[['êµ­ë¯¼ì€í–‰ ì…ì¶œê¸ˆ ìƒí’ˆì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜ ë§¤ìš° ìì„¸í•˜ê²Œ', 'êµ­ë¯¼ì€í–‰ì˜ ì…ì¶œê¸ˆ ìƒí’ˆ ì¤‘ í•˜ë‚˜ì¸ KBë§ˆì´í•í†µì¥ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\\n\\n- **ìƒí’ˆëª…**: KBë§ˆì´í•í†µì¥\\n- **ê¸°ë³¸ê¸ˆë¦¬**: 0.1%\\n- **ìµœê³ ê¸ˆë¦¬**: 1.5% (ìš°ëŒ€ê¸ˆë¦¬ í¬í•¨)\\n- **ì´ì ì§€ê¸‰ ë°©ì‹**: ë¶„ê¸° ì§€ê¸‰\\n- **ê°€ì… ë°©ë²•**: ì˜ì—…ì  ë˜ëŠ” ìŠ¤ë§ˆíŠ¸ë±…í‚¹ì„ í†µí•´ ê°€ì… ê°€ëŠ¥\\n- **ê°€ì… ëŒ€ìƒ**: ë§Œ 18ì„¸ ì´ìƒ ë§Œ 38ì„¸ ì´í•˜ì˜ ì‹¤ëª…ì˜ ê°œì¸\\n- **ê°€ì… ì œí•œ ì¡°ê±´**: ì œí•œ ì—†ìŒ\\n- **ìš°ëŒ€ ì¡°ê±´**: ì´ì ì§€ê¸‰ ì›”ì˜ ì „ì›” ë§ì¼ ê¸°ì¤€ìœ¼ë¡œ ì§ì „ 3ê°œì›” ë™ì•ˆ ì•„ë˜ì˜ ì…ê¸ˆ ì‹¤ì  ì¤‘ í•œ ê°€ì§€ë¥¼ 2ê°œì›” ì´ìƒ ì¶©ì¡±í•´ì•¼ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì œê³µë©ë‹ˆë‹¤.\\n  1. ê³ ê° ì§€ì •ì¼ì— ê±´ë³„ 50ë§Œì› ì´ìƒ ì…ê¸ˆ\\n  2. ê¸‰ì—¬ì„± ë¬¸êµ¬ê°€ í¬í•¨ëœ ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ì…ê¸ˆ\\n  3. ë‹¹í–‰ ê¸‰ì—¬ì´ì²´ ì „ì‚°ì„ í†µí•´ ì…ê¸ˆë˜ëŠ” ê±´ë³„ 50ë§Œì› ì´ìƒì˜ ê¸‰ì—¬ ì…ê¸ˆ\\n- **ê¸°íƒ€ ìœ ì˜ì‚¬í•­**:\\n  1. í•˜ë‚˜ì˜ í†µì¥ì„ ëª©ì ì— ë§ê²Œ ìª¼ê°œ ì“¸ ìˆ˜ ìˆëŠ” í†µì¥ì…ë‹ˆë‹¤ (ê¸°ë³¸ë¹„/ìƒí™œë¹„/ë¹„ìƒê¸ˆ).\\n  2. ìš°ëŒ€ ì¡°ê±´ì„ ì¶©ì¡±í•  ê²½ìš° ë§¤ì¼ì˜ ë¹„ìƒê¸ˆë°•ìŠ¤ ìµœì¢… ì”ì•¡(ìµœëŒ€ 2ë°±ë§Œì›)ì— ëŒ€í•´ ë¹„ìƒê¸ˆ ì´ìœ¨ì´ ì ìš©ë©ë‹ˆë‹¤.\\n  3. 1ì¸ 1ê³„ì¢Œë¡œ ì œí•œë©ë‹ˆë‹¤.\\n\\në” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'], ('ë§ˆì´í•í†µì¥ì— ê°€ì¥ ì í•©í•œ ì‚¬ìš©ì ìœ í˜•ì€ ì–´ë–¤ ì‚¬ëŒë“¤ì¸ê°€ìš”?', 'ë§ˆì´í•í†µì¥ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ìš©ìì—ê²Œ ì í•©í•©ë‹ˆë‹¤:\\n\\n1. **ëª©í‘œ ì €ì¶•ì„ ì›í•˜ëŠ” ì‚¬ëŒ**: íŠ¹ì •í•œ ëª©í‘œ(ì˜ˆ: ì—¬í–‰, ê²°í˜¼, êµìœ¡ë¹„ ë“±)ë¥¼ ìœ„í•´ ì €ì¶•í•˜ê³ ì í•˜ëŠ” ì‚¬ëŒ.\\n2. **ìœ ì—°í•œ ì…ì¶œê¸ˆì„ ì›í•˜ëŠ” ì‚¬ëŒ**: í•„ìš”í•  ë•Œ ì‰½ê²Œ ì…ì¶œê¸ˆì´ ê°€ëŠ¥í•œ í†µì¥ì„ ì›í•˜ëŠ” ì‚¬ëŒ.\\n3. **ê¸ˆë¦¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì‚¬ëŒ**: ì¼ë°˜ í†µì¥ë³´ë‹¤ ë†’ì€ ê¸ˆë¦¬ë¥¼ ì›í•˜ëŠ” ì‚¬ëŒ.\\n\\nì´ ì™¸ì—ë„ ê°œì¸ì˜ ì¬ì • ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ, í•„ìš”ì— ë”°ë¼ ì¶”ê°€ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. ì €ëŠ” ê¸ˆìœµìƒí’ˆ ì§ˆë¬¸ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµìƒí’ˆê´€ë ¨ ì§ˆë¬¸ì„ ì£¼ì„¸ìš”.'), ('ë§ˆì´í•í†µì¥ì— ì œì¼ ì•Œë§ì€ ì‚¬ìš©ìëŠ” ëˆ„êµ¬ì•¼?', 'ë§ˆì´í•í†µì¥ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ìš©ìì—ê²Œ ì í•©í•©ë‹ˆë‹¤:\\n\\n1. **ëª©í‘œ ì €ì¶•ì„ ì›í•˜ëŠ” ì‚¬ëŒ**: íŠ¹ì •í•œ ëª©í‘œ(ì˜ˆ: ì—¬í–‰, ê²°í˜¼, êµìœ¡ë¹„ ë“±)ë¥¼ ìœ„í•´ ì €ì¶•í•˜ê³ ì í•˜ëŠ” ì‚¬ëŒ.\\n2. **ìœ ì—°í•œ ì…ì¶œê¸ˆì„ ì›í•˜ëŠ” ì‚¬ëŒ**: í•„ìš”í•  ë•Œ ì‰½ê²Œ ì…ì¶œê¸ˆì´ ê°€ëŠ¥í•œ í†µì¥ì„ ì›í•˜ëŠ” ì‚¬ëŒ.\\n3. **ê¸ˆë¦¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì‚¬ëŒ**: ì¼ë°˜ í†µì¥ë³´ë‹¤ ë†’ì€ ê¸ˆë¦¬ë¥¼ ì›í•˜ëŠ” ì‚¬ëŒ.\\n\\nì´ ì™¸ì—ë„ ê°œì¸ì˜ ì¬ì • ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ, í•„ìš”ì— ë”°ë¼ ì¶”ê°€ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. ì €ëŠ” ê¸ˆìœµìƒí’ˆ ì§ˆë¬¸ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµìƒí’ˆê´€ë ¨ ì§ˆë¬¸ì„ ì£¼ì„¸ìš”.')]\n"
     ]
    }
   ],
   "source": [
    "# ì±—ë´‡ í´ë˜ìŠ¤\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        self.thread_id = str(uuid.uuid4())\n",
    "\n",
    "    def chat(self, message: str, history: List[Tuple[str, str]]) -> str:\n",
    "        \"\"\"\n",
    "        ì…ë ¥ ë©”ì‹œì§€ì™€ ëŒ€í™” ì´ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ Adaptive Self-RAG ì²´ì¸ì„ í˜¸ì¶œí•˜ê³ ,\n",
    "        ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        \"\"\"\n",
    "        config = {\"configurable\": {\"thread_id\": self.thread_id}}\n",
    "        state = initialize_state()\n",
    "        state[\"question\"] = message\n",
    "        \n",
    "        # historyê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "        if history:\n",
    "            state[\"history\"] = history\n",
    "        \n",
    "        result = adaptive_self_rag_memory.invoke(state, config=config)\n",
    "\n",
    "        gen_list = result.get(\"generation\", [])\n",
    "        if not gen_list:\n",
    "            bot_response = \"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            bot_response = gen_list[-1]  # ë§ˆì§€ë§‰ ìƒì„±ëœ ë‹µë³€ì„ ì‚¬ìš©\n",
    "\n",
    "        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸\n",
    "        state[\"history\"].append((message, bot_response))\n",
    "        print(f\"--- History í™•ì¸ ---\\n{state['history']}\")\n",
    "        return bot_response\n",
    "\n",
    "\n",
    "# ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "chatbot = ChatBot() \n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chatbot.chat,\n",
    "    title=\"Adaptive Self-RAG ê¸°ë°˜ RAG ì±—ë´‡ ì‹œìŠ¤í…œ\",\n",
    "    description=\"ì •ê¸°ì˜ˆê¸ˆ, ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆ ìƒí’ˆ ë° ê¸°íƒ€ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.\",\n",
    "    examples=[\n",
    "        \"ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€?\",\n",
    "        \"ì •ê¸°ì˜ˆê¸ˆê³¼ ì…ì¶œê¸ˆììœ ì˜ˆê¸ˆì€ ì–´ë–¤ ì°¨ì´ì ì´ ìˆë‚˜ìš”?\",\n",
    "        \"ì€í–‰ì˜ ì˜ˆê¸ˆ ìƒí’ˆì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.\"\n",
    "    ],\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Gradio ì•± ì‹¤í–‰: ì´ íŒŒì¼ì„ ë©”ì¸ìœ¼ë¡œ ì‹¤í–‰í•  ë•Œë§Œ ë„ì›ë‹ˆë‹¤.\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd7c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ë°˜ë³µí˜• Self-RAG ë‹µë³€ ìƒì„± ì‹œì‘ ---\n",
      "--- [k=1] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=2] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "Closing server running on port: 7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=3] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=4] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=5] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=6] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=7] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ë°˜ë³µí˜• Self-RAG ë‹µë³€ ìƒì„± ì‹œì‘ ---\n",
      "--- [k=1] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\"ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=2] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\"ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=3] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=4] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=5] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=6] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=7] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ë°˜ë³µí˜• Self-RAG ë‹µë³€ ìƒì„± ì‹œì‘ ---\n",
      "--- [k=1] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=2] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=3] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=4] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ, ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ìƒí’ˆì´ ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=5] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=6] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\"ì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=7] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ë°˜ë³µí˜• Self-RAG ë‹µë³€ ìƒì„± ì‹œì‘ ---\n",
      "--- [k=1] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=2] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n",
      "--- [k=3] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, í˜„ì¬ ì œê³µë˜ëŠ” ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=4] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ê²ƒì€ ì´ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=5] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ë¡œ, ì‹ ê·œ ê³ ê° ìš°ëŒ€ì´ìœ¨ê³¼ ì´ë²¤íŠ¸ ìš°ëŒ€ì´ìœ¨ì„ í†µí•´ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆì…ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=6] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ, ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆì…ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ì‹ ê·œ ê³ ê°ì—ê²Œ ìš°ëŒ€ì´ìœ¨ì´ ì œê³µë˜ë©°, ê°€ì… ê¸°ê°„ì— ë”°ë¼ ë‹¤ì–‘í•œ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- [k=7] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ ì œê³µë©ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ì‹ ê·œ ê³ ê°ì—ê²Œ ìš°ëŒ€ì´ìœ¨ì„ í¬í•¨í•˜ì—¬ ìµœëŒ€ 0.45%pì˜ ì¶”ê°€ ê¸ˆë¦¬ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆ ì¤‘ì—ì„œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ìƒí’ˆìœ¼ë¡œ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. \n",
      "\n",
      "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'] ---\n",
      "--- ìƒì„± 2íšŒ ì´ˆê³¼ â†’ ë°˜ë³µí˜• ìƒì„±ìœ¼ë¡œ ì „í™˜ ---\n",
      "--- ë°˜ë³µí˜• Self-RAG ë‹µë³€ ìƒì„± ì‹œì‘ ---\n",
      "--- [k=1] ë¬¸ì„œ ëˆ„ì  ê²€ìƒ‰ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ, ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆì…ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ì‹ ê·œ ê³ ê°ì—ê²Œ ìš°ëŒ€ì´ìœ¨ì´ ì œê³µë˜ë©°, ê°€ì… ê¸°ê°„ì— ë”°ë¼ ë‹¤ì–‘í•œ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ë‹µë³€-ì§ˆë¬¸ ê´€ë ¨ì„± í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì„ ì˜ í•´ê²°í•¨ ---\n",
      "--- ìœ ìš©í•œ ë‹µë³€ ë°œê²¬ ---\n",
      "--- ë‹µë³€ í‰ê°€ (ìƒì„±) ---\n",
      "--- ìƒì„±ëœ ë‹µë³€: ['ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'BNKë¶€ì‚°ì€í–‰ì˜ \"ë”(The) íŠ¹íŒ ì •ê¸°ì˜ˆê¸ˆ\" ìƒí’ˆì€ ìµœê³ ê¸ˆë¦¬ê°€ 3.2%ë¡œ, ìš°ëŒ€ê¸ˆë¦¬ë¥¼ í¬í•¨í•œ ê¸ˆë¦¬ê°€ ê°€ì¥ ë†’ì€ ì •ê¸°ì˜ˆê¸ˆ ìƒí’ˆì…ë‹ˆë‹¤. ì´ ìƒí’ˆì€ ì‹ ê·œ ê³ ê°ì—ê²Œ ìš°ëŒ€ì´ìœ¨ì´ ì œê³µë˜ë©°, ê°€ì… ê¸°ê°„ì— ë”°ë¼ ë‹¤ì–‘í•œ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ëª…ì¾Œí•œ ë‹µë³€ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'] ---\n",
      "--- ë‹µë³€ í• ë£¨ì‹œë„¤ì´ì…˜ í‰ê°€ ---\n",
      "--- ìƒì„±ëœ ë‹µë³€ì˜ ê·¼ê±°ê°€ ë¶€ì¡± -> generate ì¬ì‹œë„ ---\n"
     ]
    }
   ],
   "source": [
    "# demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
