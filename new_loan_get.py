from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import json
import re

# ------------------------------------------------------------
# ê³µí†µ ì •ë¦¬ í•¨ìˆ˜: ì¤„ë°”ê¿ˆ, íƒ­, nbsp ì œê±°í•˜ê³  ìŠ¤í˜ì´ìŠ¤ë¡œ í†µì¼
# ------------------------------------------------------------
def clean(text):
    if not isinstance(text, str):
        return ""
    return " ".join(text.replace("\n", " ").replace("\t", " ").replace("\xa0", " ").split())

# ------------------------------------------------------------
# ìƒì„¸ì •ë³´ HTML(dt/dd) íŒŒì‹± í•¨ìˆ˜
# ------------------------------------------------------------
def parse_detail_panel(detail_row):
    """
    Selenium element(detail_row)ì˜ innerHTMLì—ì„œ
    <dt>ë ˆì´ë¸”</dt><dd>ê°’</dd> ìŒì„ ëª¨ë‘ ì½ì–´ì„œ
    ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    """
    html = detail_row.get_attribute('innerHTML')
    soup = BeautifulSoup(html, 'html.parser')

    data = {}
    # dt -> ë‹¤ìŒ dd ê°’ì„ ì½ì–´ì„œ key/value ë¡œ ì €ì¥
    for dt in soup.select('dt'):
        key = dt.get_text(strip=True).rstrip(':')
        dd = dt.find_next_sibling('dd')
        if dd:
            # dd ì•ˆì˜ í…ìŠ¤íŠ¸(ì¤„ë°”ê¿ˆ, bullet í¬í•¨)ë¥¼ ê¹¨ë—ì´ ì •ë¦¬
            data[key] = clean(dd.get_text(separator=' '))
    return data

# ------------------------------------------------------------
# 1) ì£¼íƒë‹´ë³´ëŒ€ì¶œ(ë³´ê¸ˆìë¦¬ë¡  ë“±) ìŠ¤í¬ë˜í•‘
# ------------------------------------------------------------
driver = webdriver.Chrome()
wait = WebDriverWait(driver, 15)
driver.get("https://finlife.fss.or.kr/finlife/ldng/houseMrtg/list.do?menuNo=700007")

# í•œ í˜ì´ì§€ì— 50ê°œ ë³´ì´ë„ë¡ ì„¤ì •
wait.until(EC.presence_of_element_located((By.ID, "pageUnit")))
Select(driver.find_element(By.ID, "pageUnit")).select_by_visible_text("50")
time.sleep(0.5)
wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button.search.ajaxFormSearch"))).click()
time.sleep(0.5)

results = []
# ì´ 6í˜ì´ì§€(1~6)
for page_num in range(1, 7):
    print(f"ğŸ“„ [ì£¼ë‹´ëŒ€] í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì¤‘...")
    if page_num > 1:
        # í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
        links = driver.find_elements(By.CSS_SELECTOR, "ul.pagination li a[data-pageindex]")
        for a in links:
            if a.get_attribute("data-pageindex") == str(page_num):
                driver.execute_script("arguments[0].click();", a)
                time.sleep(0.5)
                wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "tbody tr")))
                break

    rows = driver.find_elements(By.CSS_SELECTOR, "tbody tr")
    for i in range(0, len(rows), 2):
        tds = rows[i].find_elements(By.TAG_NAME, "td")
        if len(tds) < 15:
            continue

        info = {
            "ê¸ˆìœµíšŒì‚¬": clean(tds[1].text),
            "ìƒí’ˆëª…": clean(tds[2].text),
            "ì£¼íƒì¢…ë¥˜": clean(tds[3].text),
            # select ë°•ìŠ¤ í…ìŠ¤íŠ¸ ë§ˆì§€ë§‰ ë‹¨ì–´ë§Œ
            "ê¸ˆë¦¬ë°©ì‹": clean(tds[4].text.split()[-1]),
            "ìƒí™˜ë°©ì‹": clean(tds[5].text.split()[-1]),
            "ìµœì €ê¸ˆë¦¬": clean(tds[6].text),
            "ìµœê³ ê¸ˆë¦¬": clean(tds[7].text),
            "ì „ì›”í‰ê· ê¸ˆë¦¬": clean(tds[8].text),
            "ë¬¸ì˜ì „í™”": clean(tds[13].text),
        }

        # ìƒì„¸ë³´ê¸° í´ë¦­
        detail_link = next(a for a in rows[i].find_elements(By.TAG_NAME, "a") if "ìƒì„¸" in a.text)
        driver.execute_script("arguments[0].scrollIntoView(true);", detail_link)
        driver.execute_script("arguments[0].click();", detail_link)
        time.sleep(0.1)

        # ë‹¤ìŒ í–‰ì´ ìƒì„¸ì •ë³´ íŒ¨ë„(tr)
        detail_row = rows[i + 1]
        detail_data = parse_detail_panel(detail_row)
        info.update(detail_data)

        results.append(info)

    print(f"âœ… [ì£¼ë‹´ëŒ€] ëˆ„ì  ìˆ˜ì§‘: {len(results)}ê°œ")

driver.quit()

# ------------------------------------------------------------
# 2) ê°œì¸ì‹ ìš©ëŒ€ì¶œ (ì‹ ìš©ëŒ€ì¶œ) ìŠ¤í¬ë˜í•‘
# ------------------------------------------------------------
driver = webdriver.Chrome()
wait = WebDriverWait(driver, 15)
driver.get("https://finlife.fss.or.kr/finlife/ldng/indvlCrdt/list.do?menuNo=700009")

# í˜ì´ì§€ë‹¹ 50ê°œ ì„¤ì •
wait.until(EC.presence_of_element_located((By.ID, "pageUnit")))
Select(driver.find_element(By.ID, "pageUnit")).select_by_visible_text("50")
time.sleep(0.5)
wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button.search.ajaxFormSearch"))).click()
time.sleep(0.5)

rows = driver.find_elements(By.CSS_SELECTOR, "tbody tr")
for i in range(0, len(rows), 2):
    tds = rows[i].find_elements(By.TAG_NAME, "td")
    if len(tds) < 14:
        continue

    info = {
        "ê¸ˆìœµíšŒì‚¬": clean(tds[0].text),
        "ëŒ€ì¶œì¢…ë¥˜": clean(tds[1].text),
        "ê¸ˆë¦¬êµ¬ë¶„": clean(tds[2].text),
        "900ì  ì´ˆê³¼": clean(tds[3].text),
        "801~900ì ": clean(tds[4].text),
        "701~800ì ": clean(tds[5].text),
        "601~700ì ": clean(tds[6].text),
        "501~600ì ": clean(tds[7].text),
        "401~500ì ": clean(tds[8].text),
        "301~400ì ": clean(tds[9].text),
        "300ì  ì´í•˜": clean(tds[10].text),
        "í‰ê· ê¸ˆë¦¬": clean(tds[11].text),
        "CBíšŒì‚¬ëª…": clean(tds[12].text),
        "ë¬¸ì˜ì „í™”": clean(tds[13].text),
    }

    # ìƒì„¸ë³´ê¸° í´ë¦­
    detail_link = next(a for a in rows[i].find_elements(By.TAG_NAME, "a") if "ìƒì„¸" in a.text)
    driver.execute_script("arguments[0].scrollIntoView(true);", detail_link)
    driver.execute_script("arguments[0].click();", detail_link)
    time.sleep(0.1)

    detail_row = rows[i + 1]
    detail_data = parse_detail_panel(detail_row)
    info.update(detail_data)

    results.append(info)

print(f"âœ… [ì‹ ìš©ëŒ€ì¶œ] ëˆ„ì  ìˆ˜ì§‘: {len(results)}ê°œ ì´í•©")

driver.quit()

# ------------------------------------------------------------
# 3) JSON ë¬¸ì„œí™”
# ------------------------------------------------------------
documents = []
for idx, item in enumerate(results):
    doc = {
        "id": f"ëŒ€ì¶œ_{idx+1:03d}",
        "bank": item.get("ê¸ˆìœµíšŒì‚¬", ""),
        "product_name": item.get("ìƒí’ˆëª…", item.get("ëŒ€ì¶œì¢…ë¥˜", "")),
        "type": "ëŒ€ì¶œ",
        "content": (
            f"{item.get('ê¸ˆìœµíšŒì‚¬','')} / "
            f"{item.get('ìƒí’ˆëª…', item.get('ëŒ€ì¶œì¢…ë¥˜',''))} / "
            f"ê¸ˆë¦¬: {item.get('ìµœì €ê¸ˆë¦¬','')}"
            f"{'~'+item['ìµœê³ ê¸ˆë¦¬'] if item.get('ìµœê³ ê¸ˆë¦¬') else ''}"
        ),
        "key_summary": (
            f"{item.get('ê¸ˆìœµíšŒì‚¬','')} / "
            f"{item.get('ìƒí’ˆëª…', item.get('ëŒ€ì¶œì¢…ë¥˜',''))} / "
            f"{item.get('í‰ê· ê¸ˆë¦¬','')}"
        ),
        "metadata": item
    }
    documents.append(doc)

with open("loan.json", "w", encoding="utf-8") as f:
    json.dump({"documents": documents}, f, ensure_ascii=False, indent=2)

print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: loan.json (ì´ {len(documents)}ê±´)")
